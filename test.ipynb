{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04d64952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class MAPConfigs:\n",
    "    model_id: str\n",
    "    num_agents: int\n",
    "    \n",
    "\n",
    "configs = MAPConfigs(\n",
    "    model_id=\"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "    num_agents=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3977ec45",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base (Python 3.13.5)' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ccf05d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/multi-agent/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "\n",
    "# Pick a sensible dtype for your hardware\n",
    "dtype = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
    "device_map = \"auto\"\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(configs.model_id, use_fast=True)\n",
    "def init_model():\n",
    "    return AutoModelForCausalLM.from_pretrained(\n",
    "        configs.model_id,\n",
    "        torch_dtype=dtype,\n",
    "        device_map=device_map,\n",
    "    )\n",
    "\n",
    "models = [init_model() for _ in range(configs.num_agents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d11e37bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "def inference(model, system_prompt, problem, max_tokens=1024, temperature=0.7):\n",
    "    client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=\"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\"  \n",
    "    )\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": problem}\n",
    "        ],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    return resp.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9bbe47a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#how should we structure this?\n",
    "#allow the models to communicate then RL them on Math?\n",
    "#let's start super early with that \n",
    "system_prompt = \"\"\"\n",
    "You are in a mulitagent env where you can communicate with eachother to help solve it together\n",
    "to communicate you can type <send> Your message to the other agent </send>\n",
    "Messages received from other agents will be show up in your context as <received>Message Sent </received>\n",
    "You are encourage to message often to help collobratively solve the problem together\n",
    "You should do some working out and send over what findings you have that you think would be helpful to the other agent\n",
    "\"\"\"\n",
    "\n",
    "problem = \"\"\"\n",
    "Solve the following MATH problem\n",
    "Convert the point $(0,3)$ in rectangular coordinates to polar coordinates. Enter your answer in the form $(r,\\theta),$ where $r > 0$ and $0 \\le \\theta < 2 \\pi.$\n",
    "\"\"\"\n",
    "\n",
    "reprompt = \"\"\"\n",
    "This is the response from the env\n",
    "\"\"\"\n",
    "\n",
    "model = \"meta-llama/llama-3.2-1b-instruct\"\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Message:\n",
    "    content:str\n",
    "    model_generated: bool\n",
    "    tokenized: list = None\n",
    "\n",
    "messages = []\n",
    "\n",
    "\n",
    "messages.append(Message(system_prompt, False))\n",
    "messages.append(Message(problem, False))\n",
    "\n",
    "output = inference(model, system_prompt, problem)\n",
    "\n",
    "messages.append(Message(output, True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2ffc3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_follow_up = \"\"\"\n",
    "{message}\n",
    "\n",
    "<recieved>\n",
    "{output}\n",
    "</recieved>\n",
    "\"\"\"\n",
    "\n",
    "output = inference(model, system_prompt, formatted_follow_up)\n",
    "output\n",
    "messages.append(Message(output, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "460fe494",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "back_prop_outputs = [message.content for message in messages if message.model_generated]\n",
    "for message in messages:\n",
    "    message.tokenized = tok(message.content).input_ids\n",
    "    \n",
    "output_ids = []\n",
    "for message in messages:\n",
    "    output_ids.extend(message.tokenized)\n",
    "\n",
    "output_ids_tensor = torch.tensor(output_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab7ec25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.4688,  8.1250, 12.0000,  ..., -1.4688, -1.4688, -1.4688],\n",
       "       dtype=torch.bfloat16, grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8791fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12.0000,  8.0625,  6.8125], dtype=torch.bfloat16,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([12.0000,  8.0625,  6.8125], dtype=torch.bfloat16,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "logits = models[0](output_ids_tensor.unsqueeze(0)).loss[\"logits\"].view(-1)\n",
    "\n",
    "backprop_logits = []\n",
    "\n",
    "index = 0 \n",
    "\n",
    "for message in messages:\n",
    "    if message.model_generated:\n",
    "        \n",
    "       \n",
    "        backprop_logits.append(logits[index: index + len(message.tokenized)])\n",
    "        \n",
    "    index += len(message.tokenized)\n",
    "\n",
    "loss = torch.tensor(-1 * backprop_logits)\n",
    "loss.backwards()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c86994e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 58916864.0\n",
      "Gradients preserved and computed successfully!\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "@dataclass\n",
    "class MAPConfigs:\n",
    "    model_id: str\n",
    "    num_agents: int\n",
    "    \n",
    "configs = MAPConfigs(\n",
    "    model_id=\"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "    num_agents=2,\n",
    ")\n",
    "\n",
    "# Pick a sensible dtype for your hardware\n",
    "dtype = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
    "device_map = \"auto\"\n",
    "tok = AutoTokenizer.from_pretrained(configs.model_id, use_fast=True)\n",
    "\n",
    "def init_model():\n",
    "    return AutoModelForCausalLM.from_pretrained(\n",
    "        configs.model_id,\n",
    "        torch_dtype=dtype,\n",
    "        device_map=device_map,\n",
    "    )\n",
    "\n",
    "models = [init_model() for _ in range(configs.num_agents)]  # Fixed the syntax error\n",
    "\n",
    "@dataclass\n",
    "class Message:\n",
    "    content: str\n",
    "    model_generated: bool\n",
    "    token_ids: torch.Tensor = None  # Store as tensor directly\n",
    "    start_idx: int = None  # Track position in combined sequence\n",
    "    end_idx: int = None\n",
    "\n",
    "def inference(model, system_prompt, problem, max_tokens=1024, temperature=0.7):\n",
    "    client = OpenAI(\n",
    "        base_url=\"https://openrouter.ai/api/v1\",\n",
    "        api_key=\"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\"  \n",
    "    )\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": problem}\n",
    "        ],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "def tokenize_and_combine_messages(messages, tokenizer):\n",
    "    \"\"\"\n",
    "    Tokenize messages and create combined tensor while preserving gradient flow\n",
    "    Returns combined tensor and updates message objects with indices\n",
    "    \"\"\"\n",
    "    all_token_tensors = []\n",
    "    current_idx = 0\n",
    "    \n",
    "    for message in messages:\n",
    "        # Tokenize to tensor directly\n",
    "        tokens = tokenizer(message.content, return_tensors=\"pt\").input_ids.squeeze(0)\n",
    "        message.token_ids = tokens\n",
    "        message.start_idx = current_idx\n",
    "        message.end_idx = current_idx + len(tokens)\n",
    "        \n",
    "        all_token_tensors.append(tokens)\n",
    "        current_idx += len(tokens)\n",
    "    \n",
    "    # Concatenate all tensors (preserves gradients)\n",
    "    combined_tokens = torch.cat(all_token_tensors, dim=0)\n",
    "    return combined_tokens\n",
    "\n",
    "def extract_model_generated_logits(logits, messages):\n",
    "    \"\"\"\n",
    "    Extract logits for model-generated messages while preserving gradients\n",
    "    \"\"\"\n",
    "    backprop_logits = []\n",
    "    \n",
    "    for message in messages:\n",
    "        if message.model_generated:\n",
    "            # Slice logits using tensor indexing (preserves gradients)\n",
    "            message_logits = logits[message.start_idx:message.end_idx]\n",
    "            backprop_logits.append(message_logits)\n",
    "    \n",
    "    return backprop_logits\n",
    "\n",
    "# Main execution\n",
    "system_prompt = \"\"\"\n",
    "You are in a multiagent env where you can communicate with each other to help solve it together\n",
    "to communicate you can type <send> Your message to the other agent </send>\n",
    "Messages received from other agents will be shown up in your context as <received>Message Sent </received>\n",
    "You are encouraged to message often to help collaboratively solve the problem together\n",
    "You should do some working out and send over what findings you have that you think would be helpful to the other agent\n",
    "\"\"\"\n",
    "\n",
    "problem = \"\"\"\n",
    "Solve the following MATH problem\n",
    "Convert the point $(0,3)$ in rectangular coordinates to polar coordinates. Enter your answer in the form $(r,\\theta),$ where $r > 0$ and $0 \\le \\theta < 2 \\pi.$\n",
    "\"\"\"\n",
    "\n",
    "model = \"meta-llama/llama-3.2-1b-instruct\"\n",
    "\n",
    "# Initialize messages\n",
    "messages = []\n",
    "messages.append(Message(system_prompt, False))\n",
    "messages.append(Message(problem, False))\n",
    "\n",
    "# Get first response\n",
    "output1 = inference(model, system_prompt, problem)\n",
    "messages.append(Message(output1, True))\n",
    "\n",
    "# Format follow-up\n",
    "formatted_follow_up = f\"\"\"\n",
    "{problem}\n",
    "<received>\n",
    "{output1}\n",
    "</received>\n",
    "\"\"\"\n",
    "\n",
    "# Get second response\n",
    "output2 = inference(model, system_prompt, formatted_follow_up)\n",
    "messages.append(Message(output2, True))\n",
    "\n",
    "# Tokenize and combine while preserving gradients\n",
    "combined_tokens = tokenize_and_combine_messages(messages, tok)\n",
    "\n",
    "# Forward pass through model\n",
    "model_output = models[0](combined_tokens.unsqueeze(0))\n",
    "logits = model_output.logits.squeeze(0)  # Remove batch dimension\n",
    "\n",
    "# Extract logits for model-generated content (preserves gradients)\n",
    "backprop_logits = extract_model_generated_logits(logits, messages)\n",
    "\n",
    "# Compute loss (example: negative log likelihood)\n",
    "total_loss = torch.tensor(0.0, requires_grad=True)\n",
    "\n",
    "for message_logits in backprop_logits:\n",
    "    # Example loss computation - you'll want to replace this with your actual loss\n",
    "    # This is just a placeholder - you need proper target tokens for real loss\n",
    "    loss_contribution = -message_logits.sum()  # Placeholder loss\n",
    "    total_loss = total_loss + loss_contribution\n",
    "\n",
    "# Now you can backpropagate!\n",
    "total_loss.backward()\n",
    "\n",
    "print(f\"Total loss: {total_loss.item()}\")\n",
    "print(\"Gradients preserved and computed successfully!\")\n",
    "\n",
    "# Alternative approach using cross-entropy loss if you have target tokens\n",
    "def compute_proper_loss(logits, target_tokens):\n",
    "    \"\"\"\n",
    "    Compute proper cross-entropy loss for language modeling\n",
    "    \"\"\"\n",
    "    # Shift logits and targets for next-token prediction\n",
    "    shift_logits = logits[:-1].contiguous()\n",
    "    shift_labels = target_tokens[1:].contiguous()\n",
    "    \n",
    "    # Flatten for cross-entropy\n",
    "    shift_logits = shift_logits.view(-1, shift_logits.size(-1))\n",
    "    shift_labels = shift_labels.view(-1)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    loss = loss_fn(shift_logits, shift_labels)\n",
    "    return loss\n",
    "\n",
    "# If you have proper target sequences, use this instead:\n",
    "# for i, message in enumerate(messages):\n",
    "#     if message.model_generated:\n",
    "#         message_logits = logits[message.start_idx:message.end_idx]\n",
    "#         target_tokens = message.token_ids\n",
    "#         loss = compute_proper_loss(message_logits, target_tokens)\n",
    "#         loss.backward(retain_graph=True)  # Use retain_graph for multiple backwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "58e90d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textarena as ta\n",
    "\n",
    "env = ta.make(env_id=\"TicTacToe-v0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eb940422",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#tool use \n",
    "\n",
    "\n",
    "def inference(model, system_prompt, problem, max_tokens=1024, temperature=0.7):\n",
    "    client = OpenAI(\n",
    "        base_url=\"https://openrouter.ai/api/v1\",\n",
    "        api_key=\"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\"  \n",
    "    )\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": problem}\n",
    "        ],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "def call_inference_tool(prompts):\n",
    "    MODEL = \"meta-llama/llama-3.2-1b-instruct\"\n",
    "    system_prompt= \"\"\n",
    "    \n",
    "    for prompt in prompts:\n",
    "        inference(MODEL, system_prompt=system_prompt, prompt=prompt)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1350f025",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt= \"\"\"\n",
    "\n",
    "You are an orchestrator for a mulitiagent RL system. Your goal is to develop a pipeline for finding the corect solution\n",
    "You have up to 10 agents working for you. \n",
    "\n",
    "You can call each one by stating \n",
    "<prompt agent=1>Solve the following</prompt>\n",
    "\n",
    "The models response will then be put in context like this\n",
    "<response>Models Response</response> \n",
    "DON\"T INCLUDE RESPONSE IN YOUR OUTPUT JSUT output all the prompts you want then i'll reprompt you with the real resposne\n",
    "\n",
    "You can set the system prompt for each with\n",
    "<system> Model System prompt e.g you are a erally skilled mathmatician</system>\n",
    "\n",
    "Here's the problem you have to collobratively solve\n",
    "Convert the point $(0,3)$ in rectangular coordinates to polar coordinates. Enter your answer in the form $(r,\\theta),$ where $r > 0$ and $0 \\le \\theta < 2 \\pi.$\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "output = inference(\"meta-llama/llama-3.2-3b-instruct\", \"\", prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "19731fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n",
      "337\n",
      "493\n",
      "666\n",
      "849\n",
      "1040\n",
      "1236\n",
      "1444\n",
      "1612\n",
      "1791\n"
     ]
    }
   ],
   "source": [
    "def extract_prompts(text):\n",
    "    index = 0\n",
    "    pairs = []\n",
    "    while text.find(\"<prompt\", index):\n",
    "        left = text.find(\"<prompt\", index)\n",
    "        right = text.find(\"prompt>\", left)\n",
    "        if right == -1: break\n",
    "        index = right\n",
    "        print(right)\n",
    "        pairs.append(text[left:right])\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "prompts = extract_prompts(output)\n",
    "\n",
    "outputs = [inference(\"meta-llama/llama-3.2-3b-instruct\", \"\", prompt) for prompt in prompts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cb2bfe09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To convert the point (0,3) in rectangular coordinates to polar coordinates, we can use the following formulas:\\n\\nr = √(x^2 + y^2)\\n\\nθ = arctan(y/x)\\n\\nPlugging in the values x = 0 and y = 3, we get:\\n\\nr = √(0^2 + 3^2) = √(0 + 9) = √9 = 3\\n\\nθ = arctan(3/0)\\n\\nSince arctan(3/0) is undefined, we need to consider the following:\\n\\n* If x = 0, then θ = π/2 (if y > 0) or -π/2 (if y < 0)\\n* Since y = 3 > 0, we choose θ = π/2\\n\\nSo, the polar coordinates of the point (0,3) are (3, π/2).',\n",
       " 'To convert from rectangular (Cartesian) coordinates to polar coordinates, we use the formulas:\\n\\nr = sqrt(x^2 + y^2)\\n\\nθ = arctan(y/x)\\n\\nwhere r is the radius (distance from the origin), θ is the angle in radians, x is the horizontal coordinate, and y is the vertical coordinate.\\n\\nIn this case, the point is (0,3), so:\\n\\nr = sqrt(0^2 + 3^2) = sqrt(0 + 9) = sqrt(9) = 3\\n\\nθ = arctan(3/0) \\n\\nSince the arctan function returns an angle in radians, we get:\\n\\nθ = π/2 (90 degrees)',\n",
       " 'To convert the point (0,3) to polar coordinates, we can use the distance formula and trigonometric identities.\\n\\nThe distance formula is:\\n\\nd = √(x^2 + y^2)\\n\\nIn this case, x = 0 and y = 3, so:\\n\\nd = √(0^2 + 3^2)\\n= √(0 + 9)\\n= √9\\n= 3\\n\\nNow, we need to find the angle θ that the line connecting the origin (0,0) and the point (0,3) makes with the positive x-axis. Since the point is directly above the origin, we can use the fact that the angle between the positive x-axis and the line is 90 degrees (or π/2 radians).\\n\\nSo, the polar coordinates of the point (0,3) are:\\n\\nr = 3\\nθ = π/2\\n\\nTherefore, the point (0,3) in polar coordinates is (3, π/2).',\n",
       " 'The standard conversion formulas for converting rectangular coordinates (x, y) to polar coordinates (r, θ) are:\\n\\nr = √(x^2 + y^2)\\n\\nθ = arctan(y/x)\\n\\nwhere r is the radius, θ is the angle, and x and y are the coordinates in rectangular space.\\n\\nUsing these formulas, we can convert the point (0, 3) from rectangular to polar coordinates as follows:\\n\\nr = √(0^2 + 3^2) = √(0 + 9) = √9 = 3\\n\\nθ = arctan(3/0) = arctan(∞) = π/2\\n\\nTherefore, the point (0, 3) in polar coordinates is (3, π/2).',\n",
       " 'To convert the point (0,3) to polar coordinates, we can use the following formulas:\\n\\nr = sqrt(x^2 + y^2)\\n\\nwhere r is the distance from the origin to the point, and x and y are the coordinates of the point.\\n\\nIn this case, x = 0 and y = 3, so we can plug these values into the formula to get:\\n\\nr = sqrt(0^2 + 3^2)\\nr = sqrt(0 + 9)\\nr = sqrt(9)\\nr = 3\\n\\nThe polar coordinate representation of the point (0,3) is (r, θ), where r is the distance from the origin to the point, and θ is the angle from the positive x-axis to the line connecting the origin to the point.\\n\\nTo find the angle θ, we can use the arctangent function:\\n\\nθ = arctan(y/x)\\nθ = arctan(3/0)\\nθ = arctan(∞)\\n\\nSince the arctan function returns the angle in radians, we can convert it to degrees by multiplying by',\n",
       " \"I'd be happy to help with the problem. However, I don't see a problem statement provided. Could you please provide the problem you'd like me to solve, and I'll do my best to assist you using the definition of polar coordinates and the relationship between rectangular and polar coordinates?\",\n",
       " 'The conversion from rectangular (Cartesian) coordinates to polar coordinates can be proven using a combination of mathematical induction and geometric reasoning.\\n\\nLet (x, y) be any point in the Cartesian plane and (r, θ) be its corresponding polar coordinates. We will use mathematical induction to prove that the following formula holds for all points in the Cartesian plane:\\n\\nr = √(x^2 + y^2) ... (1)\\n\\nBase case: The base case is when x = 0 and y = 0. In this case, we have r = √(0^2 + 0^2) = 0, which is the origin point. This is true since the polar coordinate of the origin is defined to be (r, θ) = (0, θ) for any value of θ.\\n\\nInductive step: Assume that the formula (1) is true for all points (x, y) with x ≤ a. We need to show that it is true for x = a. Let (a, b) be any point in the Cartesian plane with x = a and y = b. We can draw a line from the origin O to (a, b) and a line from O to (a, 0). The angle between these two lines is θ = arctan(b/a). Then, we can construct a circle centered at O with radius r = √(a^2 + b^2) that passes through (a, b). The polar coordinate of (a, b) is (r, θ) = (√(a^2 + b^2), arctan(b/a)). This shows that formula (1) holds for all points (x, y) with x = a, proving the inductive step.\\n\\nTherefore, by mathematical induction, formula (1) holds for all points (x, y) in the Cartesian plane, and we have proven that:\\n\\nr = √(x^2 + y^2)\\n\\nThis is the conversion from rectangular to polar coordinates.',\n",
       " \"Sure! Here's an example of how you can approximate the conversion of the point (0,3) to polar coordinates using numerical methods:\\n\\n**Method 1: Taylor Series Expansion**\\n\\nThe Taylor series expansion of a function f(x,y) at a point (a,b) is given by:\\n\\nf(x,y) = f(a,b) + (x-a) \\\\* ∂f/∂x(a,b) + (y-b) \\\\* ∂f/∂y(a,b) + ...\\n\\nwhere ∂f/∂x and ∂f/∂y are the partial derivatives of f with respect to x and y, respectively.\\n\\nIn this case, we want to convert the point (0,3) to polar coordinates, which means we want to find the values of r and θ such that:\\n\\nr = √(x^2 + y^2)\\nθ = arctan(y/x)\\n\\nWe can use the Taylor series expansion to approximate the value of r and θ at the point (0,3).\\n\\nFirst, we need to compute the partial derivatives:\\n\\n∂r/∂x = 2x/r\\n∂r/∂y = 2y/r\\n∂θ/∂x = -y/(x^2+y^2)\\n∂θ/∂y = x/(x^2+y^2)\\n\\nEvaluating these partial derivatives at the point (0,3), we get:\\n\\n∂r/∂x(0,3) = 0\\n∂r/∂y(0,3) = 6/√9 = 2\\n∂θ/∂x(0,3) = -3/9 = -1/3\\n∂θ/∂y(0,3) = 0\\n\\nNow, we can plug these values into the Taylor series expansion:\\n\\nr ≈ r(0,3) + (0-0) \\\\* ∂r/∂x(0,3) + (3-3) \\\\* ∂r/∂y(0,3) + (0-0) \\\\* ∂θ/∂x(0,3) + (3-3) \\\\* ∂θ/∂y(0,3)\\n= 3 + 0 + 0 + 0 + 0\\n= 3\\n\\nθ ≈ θ(0,3) + (0-0) \\\\* ∂θ/∂x(0,3) + (3-3) \\\\* ∂θ/∂y(0,3) + (0-0) \\\\* ∂r/∂x(0,3) + (3-3) \\\\* ∂r/∂y(0,3)\\n= arctan(3/0) + 0 + 0 + 0 + 0\\n= π/2\\n\\nTherefore, the Taylor series expansion gives us an approximation of the polar coordinates (r,θ) = (3,π/2).\\n\\n**Method 2: Numerical Integration**\\n\\nAnother way to approximate the conversion of the point (0,3) to polar coordinates is to use numerical integration.\\n\\nWe can use the formula:\\n\\nθ = arctan(y/x)\\n\\nTo approximate the value of θ, we can use a numerical integration method such as the trapezoidal rule or Simpson's rule. Let's use the trapezoidal rule:\\n\\nθ ≈ ∫(y/x) dx\\n= ∫(3/0) dx\\n= ∫∞ 0 (3/x) dx\\n\\nUsing the trapezoidal rule, we can approximate the integral:\\n\\nθ ≈ (3/0) \\\\* (h/2) + (3/1) \\\\* (1)\\n= ∞ (3/h) + 3\\n\\nwhere h is the step size. Let's choose a step size of h = 0.01. Then:\\n\\nθ ≈ (3/0) \\\\* (0.01/2) + (3/1) \\\\* (1)\\n= (0.015) + 3\\n= 3.015\\n\\nTherefore, the numerical integration gives us an approximation of the polar angle θ ≈ 3.015.\\n\\nNote that the value of θ obtained from numerical integration is slightly different from the value obtained from the Taylor series expansion. This is because the Taylor series expansion assumes a specific point (0,3) and may not capture the underlying behavior of the function near that point. Numerical integration, on the other hand, can handle a wider range of points and provides a more general approximation of the polar coordinates.\",\n",
       " 'In the rectangular coordinate system, the point (0,3) is located on the y-axis, 3 units above the origin (0,0).\\n\\nIn the polar coordinate system, the point (0,3) is located on the positive y-axis, 3 units away from the origin (0,0).\\n\\nHere is a visual representation of the point (0,3) in both coordinate systems:\\n\\nRectangular Coordinate System:\\n\\nThe point (0,3) is located on the y-axis, 3 units above the origin (0,0).\\n\\nPolar Coordinate System:\\n\\nThe point (0,3) is located on the positive y-axis, 3 units away from the origin (0,0).\\n\\nLet me know if you have any questions or need further clarification!',\n",
       " 'To convert the point (0,3) to polar coordinates using the principles of special relativity and the Lorentz transformation, we need to follow these steps:\\n\\n1. First, we need to find the Lorentz transformation matrix for the given point (0,3). The Lorentz transformation matrix is given by:\\n\\nLorentz Transformation Matrix = \\\\begin{bmatrix} \\\\gamma & -\\\\gamma \\\\beta & 0 & 0 \\\\\\\\ -\\\\gamma \\\\beta & \\\\gamma & 0 & 0 \\\\\\\\ 0 & 0 & 1 & 0 \\\\\\\\ 0 & 0 & 0 & 1 \\\\end{bmatrix}\\n\\nwhere γ is the Lorentz factor, β is the relative velocity between the two frames, and the coordinates (x, y) are the coordinates of the point in the original frame.\\n\\n2. Next, we need to find the Lorentz factor γ and the relative velocity β. Since the point (0,3) is in the x-y plane, we can assume that the relative velocity β is zero. This is because the point is not moving in the x-direction, so the Lorentz factor γ is simply 1.\\n\\n3. Now, we can plug in the values of γ and β into the Lorentz transformation matrix to get:\\n\\nLorentz Transformation Matrix = \\\\begin{bmatrix} 1 & 0 & 0 & 0 \\\\\\\\ 0 & 1 & 0 & 0 \\\\\\\\ 0 & 0 & 1 & 0 \\\\\\\\ 0 & 0 & 0 & 1 \\\\end{bmatrix}\\n\\n4. To convert the point (0,3) to polar coordinates, we need to find the radial distance r and the angle θ. The radial distance r is given by:\\n\\nr = √(x^2 + y^2)\\n\\nwhere x and y are the coordinates of the point in the original frame.\\n\\n5. The angle θ is given by:\\n\\nθ = arctan(y/x)\\n\\nSince the point (0,3) is on the y-axis, the angle θ is simply π/2.\\n\\n6. Therefore, the polar coordinates of the point (0,3) are (r, θ) = (3, π/2).\\n\\nNote that the polar coordinates (r, θ) are not unique, as there are infinitely many points on the y-axis that have the same polar coordinates. However, in this case, we have a unique solution (r, θ) = (3, π/2) because the point (0,3) is a single point in the x-y plane.']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7719ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "rewards = torch.arange(10).float()\n",
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f0d8901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.4863, -1.1560, -0.8257, -0.4954, -0.1651,  0.1651,  0.4954,  0.8257,\n",
       "         1.1560,  1.4863])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rewards - torch.mean(rewards))/torch.std(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0f0252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"gpt2\"  # or \"gpt2-medium\", \"gpt2-large\", \"gpt2-xl\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "ref_model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae0ce4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_output = torch.ones([1, 3, tokenizer.vocab_size]).float()\n",
    "expected_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71844bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(\"Hello World!\")\n",
    "input_ids = torch.tensor(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3150eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ouputs = model(input_ids.unsqueeze(0)).logits\n",
    "probs = torch.nn.Softmax(dim=-1)(ouputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc84c78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs/ probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc892b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rewards = torch.ones(4)\n",
    "\n",
    "float_rewards = rewards.float()\n",
    "reward_mean = torch.mean(float_rewards)\n",
    "reward_std = torch.std(float_rewards)\n",
    "\n",
    "advantage = (float_rewards -reward_mean)/reward_std\n",
    "advantage= torch.nan_to_num(advantage, 0)\n",
    "advantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "971b7850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(advantage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef35f01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_probs = torch.tensor([])\n",
    "ref_model_probs = torch.tensor([])\n",
    "advantage = torch.tensor([])\n",
    "\n",
    "float_rewards = rewards.float()\n",
    "reward_mean = torch.mean(float_rewards)\n",
    "reward_std = torch.std(float_rewards)\n",
    "\n",
    "advantage = (float_rewards -reward_mean)/reward_std\n",
    "\n",
    "\n",
    "formatted_string = torch.tensor([rollout.format_conversation_str for rollout in rollouts])\n",
    "inputs_ids = torch.tensor([tokenizer.encode(string) for string in  formatted_string])\n",
    "\n",
    "\n",
    "\n",
    "model_logits = torch.concat(model(inputs_ids))\n",
    "ref_model_logits = torch.concat(ref_model(inputs_ids))\n",
    "\n",
    "model_probs = torch.log(model_logits)\n",
    "ref_model_probs = torch.log(ref_model_logits)\n",
    "\n",
    "ratios = model_probs/ ref_model_probs\n",
    "\n",
    "clipped_min = torch.clip(ratios, 1-eps, 1+eps)\n",
    "\n",
    "loss = torch.min(ratios, clipped_min)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40522c93",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'advantage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43madvantage\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'advantage' is not defined"
     ]
    }
   ],
   "source": [
    "len(advantage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
